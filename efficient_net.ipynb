{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kerker\n",
      "9/9 [==============================] - 75s 5s/step - loss: 0.1946 - val_loss: 0.0571\n",
      "hello\n",
      "1/1 [==============================] - 4s 4s/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 49152 into shape (128,128)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 88\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n):\n\u001b[0;32m     87\u001b[0m     ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m3\u001b[39m, n, i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 88\u001b[0m     plt\u001b[38;5;241m.\u001b[39mimshow(\u001b[43mx_test\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m)\u001b[49m, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     89\u001b[0m     plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moriginal\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     90\u001b[0m     ax\u001b[38;5;241m.\u001b[39mget_xaxis()\u001b[38;5;241m.\u001b[39mset_visible(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 49152 into shape (128,128)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, losses, Model\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "from tensorflow.keras.applications import EfficientNetB7\n",
    "# 設定資料夾路徑\n",
    "allblackwhite_dir = './allblackwhite'\n",
    "pymatting_outcome_rw_dir = './pymatting_outcome_rw'\n",
    "\n",
    "# 讀取圖片和標籤\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder, filename), cv2.IMREAD_GRAYSCALE)\n",
    "        if img is not None:\n",
    "            img_resized = cv2.resize(img, (128, 128))\n",
    "            images.append(img_resized)\n",
    "    return np.array(images)\n",
    "\n",
    "x = load_images_from_folder(allblackwhite_dir)\n",
    "y = load_images_from_folder(pymatting_outcome_rw_dir)\n",
    "\n",
    "# 資料分割\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# 重塑圖片維度\n",
    "x_train = x_train.reshape((x_train.shape[0], 128, 128, 1))\n",
    "y_train = y_train.reshape((y_train.shape[0], 128, 128, 1))\n",
    "x_test = x_test.reshape((x_test.shape[0], 128, 128, 1))\n",
    "y_test = y_test.reshape((y_test.shape[0], 128, 128, 1))\n",
    "x_train = np.repeat(x_train, 3, axis=-1)\n",
    "y_train = np.repeat(y_train, 3, axis=-1)\n",
    "x_test = np.repeat(x_test, 3, axis=-1)\n",
    "y_test = np.repeat(y_test, 3, axis=-1)\n",
    "\n",
    "# 標準化圖片 \n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "y_train = y_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "y_test = y_test.astype('float32') / 255.0\n",
    "\n",
    "# 建立DenseNet模型\n",
    "def build_EfficientNetB7(input_shape):\n",
    "    base_model = EfficientNetB7(include_top=False, input_shape=input_shape,weights='imagenet')\n",
    "    base_model.trainable = True\n",
    "\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    x = base_model(inputs, training=True)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    x = layers.Dense(128 * 128, activation='sigmoid')(x)\n",
    "    outputs = layers.Reshape((128, 128, 1))(x)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "input_shape = (128, 128, 3)\n",
    "EfficientNetB7_model = build_EfficientNetB7(input_shape)\n",
    "EfficientNetB7_model.compile(optimizer=Adam(), loss=losses.MeanSquaredError())\n",
    "print('kerker')\n",
    "# 訓練模型\n",
    "history = EfficientNetB7_model.fit(x_train, y_train, epochs=1, shuffle=True, validation_data=(x_test, y_test))\n",
    "\n",
    "# 创建保存模型的目录\n",
    "save_dir = 'EfficientNetB7_model'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "# 保存模型为 TensorFlow SavedModel 格式\n",
    "# EfficientNetB7_model.save(os.path.join(save_dir, 'saved_model'), save_format='tf')\n",
    "\n",
    "# 加载模型\n",
    "# loaded_model = tf.keras.models.load_model(os.path.join(save_dir, 'saved_model'))\n",
    "print('hello')\n",
    "# 使用加载的模型进行预测\n",
    "decoded_imgs = EfficientNetB7_model.predict(x_test)\n",
    "\n",
    "# 可视化结果\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(3, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(128, 128), cmap='gray')\n",
    "    plt.title(\"original\")\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "    ax = plt.subplot(3, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(128, 128), cmap='gray')\n",
    "    plt.title(\"reconstructed\")\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    ax = plt.subplot(3, n, i + 1 + 2 * n)\n",
    "    plt.imshow(y_test[i].reshape(128, 128), cmap='gray')\n",
    "    plt.title(\"ground truth\")\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs = EfficientNetB7_model.predict(x_test)\n",
    "\n",
    "# 可视化结果\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(3, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(128, 128), cmap='gray')\n",
    "    plt.title(\"original\")\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "    ax = plt.subplot(3, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(128, 128), cmap='gray')\n",
    "    plt.title(\"reconstructed\")\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    ax = plt.subplot(3, n, i + 1 + 2 * n)\n",
    "    plt.imshow(y_test[i].reshape(128, 128), cmap='gray')\n",
    "    plt.title(\"ground truth\")\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
